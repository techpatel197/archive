# Advanced ASP.NET Core CI/CD Pipeline for .NET 8 with AI-Enhanced Testing and Security
# Production-ready pipeline with AI-powered unit test generation and security scanning

trigger:
  branches:
    include:
    - main
 
pool:
  vmImage: 'ubuntu-latest'

variables:
  buildConfiguration: 'Release'
  debugConfiguration: 'Debug'
  solution: 'dataarchaive.sln'
  dotNetVersion: '8.x'
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: 'true'
  DOTNET_CLI_TELEMETRY_OPTOUT: 'true'
  majorVersion: '1'
  minorVersion: '0'
  patchVersion: $[counter(format('{0}.{1}', variables['majorVersion'], variables['minorVersion']), 0)]
  buildNumber: '$(majorVersion).$(minorVersion).$(patchVersion)'

stages:
# =====================================================================
# AI-ENHANCED CONTINUOUS INTEGRATION STAGE
# =====================================================================
- stage: CI
  displayName: 'AI-Enhanced Continuous Integration'
  jobs:
  - job: AICodeAnalysis
    displayName: 'AI-Powered Code Analysis & Test Generation'
    timeoutInMinutes: 45
    steps:
    - checkout: self
      fetchDepth: 0
      clean: true

    # Setup .NET environment
    - task: UseDotNet@2
      displayName: 'Install .NET $(dotNetVersion) SDK'
      inputs:
        packageType: 'sdk'
        version: '$(dotNetVersion)'
        installationPath: $(Agent.ToolsDirectory)/dotnet

    # Install AI tools and dependencies
    - task: PowerShell@2
      displayName: 'Setup AI Analysis Tools'
      inputs:
        targetType: 'inline'
        script: |
          # Install Python for AI scripts
          sudo apt-get update
          sudo apt-get install -y python3 python3-pip
          pip3 install openai requests python-dotenv
          
          # Install Node.js for additional AI tools
          curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -
          sudo apt-get install -y nodejs
          
          # Install GitHub Copilot CLI (if available)
          npm install -g @githubnext/github-copilot-cli 2>/dev/null || echo "Copilot CLI not available"
          
          # Download AI analysis scripts
          mkdir -p $(Build.SourcesDirectory)/ai-tools

    # Create AI-powered test generation script
    - task: PowerShell@2
      displayName: 'Create AI Test Generation Script'
      inputs:
        targetType: 'inline'
        script: |
          $aiTestScript = @'
          import openai
          import os
          import sys
          import json
          import re
          from pathlib import Path
          
          # Configure OpenAI API
          openai.api_key = os.getenv('OPENAI_API_KEY')
          if not openai.api_key and os.getenv('AZURE_OPENAI_KEY'):
              openai.api_type = "azure"
              openai.api_key = os.getenv('AZURE_OPENAI_KEY')
              openai.api_base = os.getenv('AZURE_OPENAI_ENDPOINT')
              openai.api_version = "2023-12-01-preview"
          
          def analyze_csharp_file(file_path):
              """Analyze C# file and generate test suggestions"""
              try:
                  with open(file_path, 'r', encoding='utf-8') as f:
                      code = f.read()
                  
                  # Extract class and method information
                  class_matches = re.findall(r'public class (\w+)', code)
                  method_matches = re.findall(r'public.*?(\w+)\s*\([^)]*\)', code)
                  
                  return {
                      'file': str(file_path),
                      'classes': class_matches,
                      'methods': method_matches,
                      'code_snippet': code[:1000] if len(code) > 1000 else code
                  }
              except Exception as e:
                  print(f"Error analyzing {file_path}: {e}")
                  return None
          
          def generate_unit_tests(code_analysis):
              """Generate unit tests using AI"""
              if not openai.api_key:
                  print("OpenAI API key not configured, generating template tests...")
                  return generate_template_tests(code_analysis)
              
              prompt = f"""
              Analyze this C# code and generate comprehensive unit tests using xUnit:
              
              File: {code_analysis['file']}
              Classes: {', '.join(code_analysis['classes'])}
              Methods: {', '.join(code_analysis['methods'])}
              
              Code snippet:
              {code_analysis['code_snippet']}
              
              Generate:
              1. Unit tests for each public method
              2. Edge case tests (null inputs, empty collections, boundary values)
              3. Exception handling tests
              4. Integration-style tests where appropriate
              5. Use proper naming conventions and arrange-act-assert pattern
              6. Include necessary using statements and proper test class structure
              7. Use Moq for mocking dependencies if needed
              
              Return only the C# test code, properly formatted.
              """
              
              try:
                  if openai.api_type == "azure":
                      response = openai.ChatCompletion.create(
                          engine="gpt-4",
                          messages=[{"role": "user", "content": prompt}],
                          max_tokens=2000,
                          temperature=0.3
                      )
                  else:
                      response = openai.ChatCompletion.create(
                          model="gpt-4",
                          messages=[{"role": "user", "content": prompt}],
                          max_tokens=2000,
                          temperature=0.3
                      )
                  
                  return response.choices[0].message.content.strip()
              except Exception as e:
                  print(f"AI generation failed: {e}")
                  return generate_template_tests(code_analysis)
          
          def generate_template_tests(code_analysis):
              """Generate template tests when AI is unavailable"""
              class_name = code_analysis['classes'][0] if code_analysis['classes'] else 'TestClass'
              test_class = f"""using Xunit;
          using Moq;
          using System;
          using System.Collections.Generic;
          using System.Threading.Tasks;
          
          namespace DataArchive.Tests.Generated
          {{
              public class {class_name}Tests
              {{
                  private readonly {class_name} _sut;
                  
                  public {class_name}Tests()
                  {{
                      _sut = new {class_name}();
                  }}
                  
                  [Fact]
                  public void Constructor_Should_CreateInstance()
                  {{
                      // Arrange & Act
                      var result = new {class_name}();
                      
                      // Assert
                      Assert.NotNull(result);
                  }}
                  
                  [Theory]
                  [InlineData(null)]
                  [InlineData("")]
                  public void Method_WithInvalidInput_ShouldThrowException(string input)
                  {{
                      // Arrange
                      // Act & Assert
                      Assert.Throws<ArgumentException>(() => _sut.SomeMethod(input));
                  }}
              }}
          }}"""
              return test_class
          
          def main():
              if len(sys.argv) < 2:
                  print("Usage: python generate_tests.py <source_directory>")
                  return
              
              source_dir = Path(sys.argv[1])
              test_output_dir = Path("tests/Generated")
              test_output_dir.mkdir(parents=True, exist_ok=True)
              
              print(f"Analyzing C# files in {source_dir}")
              
              # Find all C# files
              cs_files = list(source_dir.rglob("*.cs"))
              cs_files = [f for f in cs_files if not any(exclude in str(f) for exclude in 
                                                        ['bin', 'obj', 'Tests', 'test', 'Program.cs', 'Startup.cs'])]
              
              results = []
              
              for cs_file in cs_files[:5]:  # Limit to prevent API exhaustion
                  print(f"Analyzing: {cs_file}")
                  analysis = analyze_csharp_file(cs_file)
                  if analysis and analysis['classes']:
                      test_code = generate_unit_tests(analysis)
                      
                      # Save generated test
                      test_filename = f"{analysis['classes'][0]}Tests.cs"
                      test_file_path = test_output_dir / test_filename
                      
                      with open(test_file_path, 'w', encoding='utf-8') as f:
                          f.write(test_code)
                      
                      results.append({
                          'source_file': str(cs_file),
                          'test_file': str(test_file_path),
                          'classes_tested': analysis['classes']
                      })
                      
                      print(f"Generated tests: {test_file_path}")
              
              # Save results summary
              with open('ai_test_generation_report.json', 'w') as f:
                  json.dump(results, f, indent=2)
              
              print(f"Generated tests for {len(results)} files")
          
          if __name__ == "__main__":
              main()
          '@
          
          $aiTestScript | Out-File -FilePath "$(Build.SourcesDirectory)/ai-tools/generate_tests.py" -Encoding UTF8

    # Cache NuGet packages
    - task: Cache@2
      displayName: 'Cache NuGet packages'
      inputs:
        key: 'nuget | "$(Agent.OS)" | **/*.csproj'
        restoreKeys: |
          nuget | "$(Agent.OS)"
          nuget
        path: '$(Pipeline.Workspace)/.nuget/packages'

    # Restore dependencies
    - task: DotNetCoreCLI@2
      displayName: '1. Restore Dependencies'
      inputs:
      command: 'restore'
      projects: '$(solution)'

    # Build solution
    - task: DotNetCoreCLI@2
      displayName: '2. Build Solution'
      inputs:
        command: 'build'
        projects: '$(solution)'
        arguments: '--configuration $(debugConfiguration) --no-restore --verbosity normal'

    # AI-powered unit test generation
    - task: PowerShell@2
      displayName: '3. AI-Powered Unit Test Generation'
      env:
        OPENAI_API_KEY: $(OPENAI_API_KEY)
        AZURE_OPENAI_KEY: $(AZURE_OPENAI_KEY)
        AZURE_OPENAI_ENDPOINT: $(AZURE_OPENAI_ENDPOINT)
      inputs:
        targetType: 'inline'
        script: |
          Write-Host "ü§ñ Starting AI-powered unit test generation..."
          
          # Run AI test generation
          python3 "$(Build.SourcesDirectory)/ai-tools/generate_tests.py" "src/"
          
          # Create test project if it doesn't exist
          if (!(Test-Path "tests/Generated/Generated.Tests.csproj")) {
              New-Item -ItemType Directory -Path "tests/Generated" -Force
              
              $testProject = @'
          <Project Sdk="Microsoft.NET.Sdk">
            <PropertyGroup>
              <TargetFramework>net8.0</TargetFramework>
              <IsPackable>false</IsPackable>
            </PropertyGroup>
            <ItemGroup>
              <PackageReference Include="Microsoft.NET.Test.Sdk" Version="17.8.0" />
              <PackageReference Include="xunit" Version="2.4.2" />
              <PackageReference Include="xunit.runner.visualstudio" Version="2.4.5" />
              <PackageReference Include="Moq" Version="4.20.69" />
              <PackageReference Include="FluentAssertions" Version="6.12.0" />
            </ItemGroup>
            <ItemGroup>
              <ProjectReference Include="../../src/DataArchive.Web/DataArchive.Web.csproj" />
            </ItemGroup>
          </Project>
          '@
              $testProject | Out-File -FilePath "tests/Generated/Generated.Tests.csproj" -Encoding UTF8
          }
          
          # Restore and build generated tests
          if (Test-Path "ai_test_generation_report.json") {
              Write-Host "‚úÖ AI test generation completed"
              dotnet restore "tests/Generated/Generated.Tests.csproj"
              dotnet build "tests/Generated/Generated.Tests.csproj" --no-restore
          } else {
              Write-Host "‚ö†Ô∏è No tests generated - creating placeholder"
          }

    # AI-Enhanced Security Analysis
    - task: PowerShell@2
      displayName: '4. AI-Powered Security Analysis'
      env:
        OPENAI_API_KEY: $(OPENAI_API_KEY)
        AZURE_OPENAI_KEY: $(AZURE_OPENAI_KEY)
        AZURE_OPENAI_ENDPOINT: $(AZURE_OPENAI_ENDPOINT)
      inputs:
        targetType: 'inline'
        script: |
          Write-Host "üîí Starting AI-powered security analysis..."
          
          # Create AI security analysis script
          $securityScript = @'
          import openai
          import os
          import sys
          import json
          import re
          from pathlib import Path
          
          # Configure OpenAI API
          openai.api_key = os.getenv('OPENAI_API_KEY')
          if not openai.api_key and os.getenv('AZURE_OPENAI_KEY'):
              openai.api_type = "azure"
              openai.api_key = os.getenv('AZURE_OPENAI_KEY')
              openai.api_base = os.getenv('AZURE_OPENAI_ENDPOINT')
              openai.api_version = "2023-12-01-preview"
          
          def analyze_security_patterns(file_path):
              """Analyze C# file for security vulnerabilities"""
              try:
                  with open(file_path, 'r', encoding='utf-8') as f:
                      code = f.read()
                  
                  # Basic pattern detection
                  vulnerabilities = []
                  
                  # SQL Injection patterns
                  if re.search(r'string.*sql.*\+.*', code, re.IGNORECASE):
                      vulnerabilities.append("Potential SQL Injection - String concatenation in SQL")
                  
                  # XSS patterns
                  if re.search(r'Html\.Raw\(.*\)', code):
                      vulnerabilities.append("Potential XSS - Html.Raw usage")
                  
                  # Hard-coded secrets
                  if re.search(r'(password|secret|key)\s*=\s*["\'][^"\']+["\']', code, re.IGNORECASE):
                      vulnerabilities.append("Potential hard-coded secret")
                  
                  # Deserialization
                  if 'JsonConvert.DeserializeObject' in code and 'TypeNameHandling' in code:
                      vulnerabilities.append("Potential unsafe deserialization")
                  
                  return {
                      'file': str(file_path),
                      'vulnerabilities': vulnerabilities,
                      'code_snippet': code[:2000] if len(code) > 2000 else code
                  }
              except Exception as e:
                  print(f"Error analyzing {file_path}: {e}")
                  return None
          
          def ai_security_review(file_analysis):
              """Get AI security review"""
              if not openai.api_key:
                  return file_analysis['vulnerabilities']
              
              prompt = f"""
              Perform a comprehensive security analysis of this C# code:
              
              File: {file_analysis['file']}
              
              Code:
              {file_analysis['code_snippet']}
              
              Analyze for:
              1. SQL Injection vulnerabilities
              2. Cross-Site Scripting (XSS) risks
              3. Authentication and authorization flaws
              4. Input validation issues
              5. Cryptographic weaknesses
              6. Information disclosure risks
              7. CSRF vulnerabilities
              8. Insecure direct object references
              9. Security misconfigurations
              10. Unsafe deserialization
              
              Provide:
              - Severity level (Critical, High, Medium, Low)
              - Specific line references if possible
              - Mitigation recommendations
              
              Format as JSON with vulnerability objects containing: type, severity, description, recommendation
              """
              
              try:
                  if openai.api_type == "azure":
                      response = openai.ChatCompletion.create(
                          engine="gpt-4",
                          messages=[{"role": "user", "content": prompt}],
                          max_tokens=1500,
                          temperature=0.2
                      )
                  else:
                      response = openai.ChatCompletion.create(
                          model="gpt-4",
                          messages=[{"role": "user", "content": prompt}],
                          max_tokens=1500,
                          temperature=0.2
                      )
                  
                  ai_response = response.choices[0].message.content.strip()
                  
                  # Try to parse JSON response
                  try:
                      import json
                      vulnerabilities = json.loads(ai_response)
                      return vulnerabilities
                  except:
                      # If not JSON, return as text analysis
                      return [{"type": "AI Analysis", "severity": "Info", "description": ai_response}]
                      
              except Exception as e:
                  print(f"AI security analysis failed: {e}")
                  return file_analysis['vulnerabilities']
          
          def main():
              source_dir = Path("src")
              output_dir = Path("security-reports")
              output_dir.mkdir(exist_ok=True)
              
              print("üîç Analyzing C# files for security vulnerabilities...")
              
              cs_files = list(source_dir.rglob("*.cs"))
              cs_files = [f for f in cs_files if not any(exclude in str(f) for exclude in 
                                                        ['bin', 'obj', 'Tests', 'test'])]
              
              all_vulnerabilities = []
              
              for cs_file in cs_files[:10]:  # Limit to prevent API exhaustion
                  print(f"Analyzing: {cs_file}")
                  analysis = analyze_security_patterns(cs_file)
                  if analysis:
                      ai_vulns = ai_security_review(analysis)
                      
                      file_report = {
                          'file': analysis['file'],
                          'pattern_vulnerabilities': analysis['vulnerabilities'],
                          'ai_vulnerabilities': ai_vulns
                      }
                      all_vulnerabilities.append(file_report)
              
              # Generate security report
              with open('security-reports/ai_security_analysis.json', 'w') as f:
                  json.dump(all_vulnerabilities, f, indent=2)
              
              # Generate summary
              total_issues = sum(len(f['pattern_vulnerabilities']) + 
                               (len(f['ai_vulnerabilities']) if isinstance(f['ai_vulnerabilities'], list) else 1)
                               for f in all_vulnerabilities)
              
              summary = f"""# AI Security Analysis Report
              
              ## Summary
              - Files analyzed: {len(all_vulnerabilities)}
              - Total potential issues found: {total_issues}
              - Analysis date: {os.popen('date').read().strip()}
              
              ## High-Priority Issues
              """
              
              for file_report in all_vulnerabilities:
                  if file_report['pattern_vulnerabilities']:
                      summary += f"\\n### {file_report['file']}\\n"
                      for vuln in file_report['pattern_vulnerabilities']:
                          summary += f"- ‚ö†Ô∏è {vuln}\\n"
              
              with open('security-reports/security_summary.md', 'w') as f:
                  f.write(summary)
              
              print(f"Security analysis complete. Found {total_issues} potential issues.")
          
          if __name__ == "__main__":
              main()
          '@
          
          $securityScript | Out-File -FilePath "$(Build.SourcesDirectory)/ai-tools/security_analysis.py" -Encoding UTF8
          
          # Run security analysis
          python3 "$(Build.SourcesDirectory)/ai-tools/security_analysis.py"

    # Install additional security tools
    - task: PowerShell@2
      displayName: '5. Install Security Scanning Tools'
      inputs:
        targetType: 'inline'
        script: |
          # Install DevSkim
          dotnet tool install --global Microsoft.CST.DevSkim.CLI --version 0.7.104
          
          # Install security code scanner
          dotnet tool install --global security-scan --version 5.6.7
          
          # Install OWASP Dependency Check
          $depCheckUrl = "https://github.com/jeremylong/DependencyCheck/releases/download/v8.4.3/dependency-check-8.4.3-release.zip"
          Invoke-WebRequest -Uri $depCheckUrl -OutFile "dependency-check.zip"
          Expand-Archive -Path "dependency-check.zip" -DestinationPath "." -Force

    # Run comprehensive security scans
    - task: PowerShell@2
      displayName: '6. Run Security Scans'
      inputs:
        targetType: 'inline'
        script: |
          Write-Host "üîç Running comprehensive security scans..."
          
          # DevSkim scan
          Write-Host "Running DevSkim..."
          devskim analyze . --output-file "security-reports/devskim-report.json" --output-format json
          
          # Security code scan
          Write-Host "Running Security Code Scan..."
          security-scan . --output "security-reports/security-scan-report.json" --format json || $true
          
          # Dependency vulnerability check
          Write-Host "Running OWASP Dependency Check..."
          ./dependency-check/bin/dependency-check.sh `
            --project "DataArchive" `
            --scan . `
            --format JSON `
            --out security-reports/dependency-check `
            --suppression dependency-check-suppressions.xml `
            --nvdApiKey e12a3546-53a3-40f0-9c61-235084b71c9f || $true
          
          # Check for vulnerable packages
          Write-Host "Checking for vulnerable NuGet packages..."
          dotnet list package --vulnerable --include-transitive > security-reports/vulnerable-packages.txt || $true

    # Run all tests including generated ones
    - task: DotNetCoreCLI@2
      displayName: '7. Run All Tests with Coverage'
      inputs:
        command: 'test'
        projects: '$(solution)'
        arguments: |
          --configuration $(debugConfiguration) 
          --no-build 
          --logger trx 
          --collect:"XPlat Code Coverage" 
          --settings coverlet.runsettings 
          --results-directory $(Agent.TempDirectory)/TestResults

    # AI-powered test result analysis
    - task: PowerShell@2
      displayName: '8. AI Test Result Analysis'
      env:
        OPENAI_API_KEY: $(OPENAI_API_KEY)
        AZURE_OPENAI_KEY: $(AZURE_OPENAI_KEY)
        AZURE_OPENAI_ENDPOINT: $(AZURE_OPENAI_ENDPOINT)
      inputs:
        targetType: 'inline'
        script: |
          Write-Host "üìä Analyzing test results with AI..."
          
          # Parse test results
          $testResults = Get-ChildItem -Path "$(Agent.TempDirectory)/TestResults" -Filter "*.trx" -Recurse
          
          if ($testResults) {
              $testSummary = @()
              foreach ($result in $testResults) {
                  [xml]$trxContent = Get-Content $result.FullName
                  $testSummary += "Test file: $($result.Name)"
                  $testSummary += "Total: $($trxContent.TestRun.ResultSummary.Counters.total)"
                  $testSummary += "Passed: $($trxContent.TestRun.ResultSummary.Counters.passed)"
                  $testSummary += "Failed: $($trxContent.TestRun.ResultSummary.Counters.failed)"
                  $testSummary += "---"
              }
              
              $testSummary | Out-File -FilePath "test-analysis-summary.txt"
              Write-Host "Test summary created for AI analysis"
          }

    # Publish test results
    - task: PublishTestResults@2
      displayName: '9. Publish Test Results'
      condition: succeededOrFailed()
      inputs:
        testResultsFormat: 'VSTest'
        testResultsFiles: '**/*.trx'
        searchFolder: '$(Agent.TempDirectory)/TestResults'
        mergeTestResults: true
        buildConfiguration: '$(debugConfiguration)'

    # Publish code coverage
    - task: PublishCodeCoverageResults@1
      displayName: '10. Publish Code Coverage'
      condition: succeededOrFailed()
      inputs:
        codeCoverageTool: 'Cobertura'
        summaryFileLocation: '$(Agent.TempDirectory)/TestResults/**/coverage.cobertura.xml'

    # Publish AI analysis artifacts
    - task: PublishPipelineArtifact@1
      displayName: '11. Publish AI Analysis Reports'
      condition: succeededOrFailed()
      inputs:
        targetPath: 'security-reports'
        artifact: 'AISecurityReports'
        publishLocation: 'pipeline'

    - task: PublishPipelineArtifact@1
      displayName: '12. Publish Generated Tests'
      condition: succeededOrFailed()
      inputs:
        targetPath: 'tests/Generated'
        artifact: 'GeneratedTests'
        publishLocation: 'pipeline'

    # AI-powered failure analysis
    - task: PowerShell@2
      displayName: '13. AI Failure Analysis'
      condition: failed()
      env:
        OPENAI_API_KEY: $(OPENAI_API_KEY)
        AZURE_OPENAI_KEY: $(AZURE_OPENAI_KEY)
        AZURE_OPENAI_ENDPOINT: $(AZURE_OPENAI_ENDPOINT)
      inputs:
        targetType: 'inline'
        script: |
          Write-Host "üö® Build failed - Running AI failure analysis..."
          
          # Collect build logs (this would need to be implemented based on your logging setup)
          $failureContext = @"
          Build failed at stage: $(System.StageName)
          Job: $(System.JobName)
          Trigger: $(Build.Reason)
          Branch: $(Build.SourceBranch)
          Commit: $(Build.SourceVersion)
          
          Recent commits:
          $(git log --oneline -5)
          "@
          
          $failureContext | Out-File -FilePath "failure-context.txt"
          
          Write-Host "Failure context saved for analysis"
          Write-Host "Manual investigation required:"
          Write-Host "1. Check security scan results for blocking issues"
          Write-Host "2. Review generated test compilation errors"
          Write-Host "3. Validate API keys and permissions"
          Write-Host "4. Check dependency conflicts"

# =====================================================================
# QUALITY GATE STAGE
# =====================================================================
- stage: QualityGate
  displayName: 'Quality Gate & Compliance'
  dependsOn: CI
  condition: succeeded()
  jobs:
  - job: QualityAssessment
    displayName: 'AI-Enhanced Quality Assessment'
    steps:
    - checkout: none
    
    - task: DownloadPipelineArtifact@2
      displayName: 'Download AI Security Reports'
      inputs:
        artifact: 'AISecurityReports'
        path: '$(System.ArtifactsDirectory)/security-reports'

    - task: PowerShell@2
      displayName: 'Quality Gate Evaluation'
      inputs:
        targetType: 'inline'
        script: |
          Write-Host "üéØ Evaluating quality gates..."
          
          $qualityGatePassed = $true
          $issues = @()
          
          # Check security scan results
          if (Test-Path "$(System.ArtifactsDirectory)/security-reports/ai_security_analysis.json") {
              $securityReport = Get-Content "$(System.ArtifactsDirectory)/security-reports/ai_security_analysis.json" | ConvertFrom-Json
              
              $criticalIssues = 0
              $highIssues = 0
              
              foreach ($file in $securityReport) {
                  $criticalIssues += ($file.ai_vulnerabilities | Where-Object { $_.severity -eq "Critical" }).Count
                  $highIssues += ($file.ai_vulnerabilities | Where-Object { $_.severity -eq "High" }).Count
              }
              
              Write-Host "Security Issues Found:"
              Write-Host "  Critical: $criticalIssues"
              Write-Host "  High: $highIssues"
              
              if ($criticalIssues -gt 0) {
                  $qualityGatePassed = $false
                  $issues += "‚ùå Critical security issues found: $criticalIssues"
              }
              
              if ($highIssues -gt 5) {
                  $qualityGatePassed = $false
                  $issues += "‚ùå Too many high-severity security issues: $highIssues (max: 5)"
              }
          }
          
          # Evaluate quality gate
          if ($qualityGatePassed) {
              Write-Host "‚úÖ Quality gate PASSED"
              Write-Host "##vso[task.setvariable variable=QualityGateResult;]Passed"
          } else {
              Write-Host "‚ùå Quality gate FAILED"
              Write-Host "Issues:"
              $issues | ForEach-Object { Write-Host "  $_" }
              Write-Host "##vso[task.setvariable variable=QualityGateResult;]Failed"
              Write-Host "##vso[task.logissue type=error]Quality gate failed due to security issues"
              exit 1
          }

# =====================================================================
# PACKAGING STAGE
# =====================================================================
- stage: Package
  displayName: 'Package Application'
  dependsOn: 
  - CI
  - QualityGate
  condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/main'))
  jobs:
  - job: BuildPackage
    displayName: 'Build and Package'
    steps:
    - checkout: self

    - task: UseDotNet@2
      displayName: 'Install .NET $(dotNetVersion) SDK'
      inputs:
        packageType: 'sdk'
        version: '$(dotNetVersion)'

    - task: DotNetCoreCLI@2
      displayName: 'Build Release Version'
      inputs:
        command: 'build'
        projects: '$(solution)'
        arguments: '--configuration Release -p:Version=$(buildNumber)'

    - task: DotNetCoreCLI@2
      displayName: 'Publish Application'
      inputs:
        command: 'publish'
        projects: '**/DataArchive.Web.csproj'
        arguments: |
          --configuration Release 
          --output $(Build.ArtifactStagingDirectory)/app 
          --self-contained false
        publishWebProjects: false

    - task: PublishPipelineArtifact@1
      displayName: 'Publish Application Artifact'
      inputs:
        targetPath: '$(Build.ArtifactStagingDirectory)/app'
        artifact: 'Application'
        publishLocation: 'pipeline'